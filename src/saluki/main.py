import argparse
import logging
import sys

from saluki.consume import consume
from saluki.listen import listen
from saluki.utils import parse_kafka_uri

logger = logging.getLogger("saluki")
logging.basicConfig(level=logging.INFO)

_LISTEN = "listen"
_CONSUME = "consume"
_PLAY = "play"
_SNIFF = "sniff"
_BURY = "bury"
_DIG = "dig"

def main() -> None:
    parser = argparse.ArgumentParser(
        prog="saluki",
        description="serialise/de-serialise flatbuffers and consume/produce from/to kafka",
    )

    parent_parser = argparse.ArgumentParser(add_help=False)
    #TODO this needs restructuring. consider having a topic_parser with partition options etc. 
    # because -m and -g does not make sense for saluki listen. 
    parent_parser.add_argument("topic", type=str, help="Kafka topic. format is broker<:port>/topic")

    parent_parser.add_argument(
        "-X",
        "--kafka-config",
        help="kafka options to pass through to librdkafka",
        required=False,
        default=None,
    )
    parent_parser.add_argument(
        "-l",
        "--log-file",
        help="filename to output all data to",
        required=False,
        default=None,
        type=argparse.FileType("a"),
    )

    sub_parsers = parser.add_subparsers(help="sub-command help", required=True, dest="command")

    sniff_parser = sub_parsers.add_parser(_SNIFF, help="sniff - broker metadata")
    sniff_parser.add_argument("broker", type=str)

    consumer_parser = argparse.ArgumentParser(add_help=False)
    consumer_parser.add_argument(
        "-e",
        "--entire",
        help="show all elements of an array in a message (truncated by default)",
        default=False,
        required=False,
    )

    consumer_mode_parser = sub_parsers.add_parser(
        _CONSUME, help="consumer mode", parents=[parent_parser, consumer_parser]
    )
    consumer_mode_parser.add_argument(
        "-m",
        "--messages",
        help="How many messages to go back",
        type=int,
        required=False,
        default=1,
    )
    consumer_mode_parser.add_argument(
        "-o", "--offset", help="offset to consume from", type=int, required=False
    )
    consumer_mode_parser.add_argument("-s", "--schema", required=False, default="auto", type=str)
    consumer_mode_parser.add_argument("-g", "--go-forwards", required=False, action="store_true")
    consumer_mode_parser.add_argument("-p", "--partition", required=False, type=int, default=0)
    consumer_mode_parser.add_argument("-f", "--filter", required=False, action="append")

    listen_parser = sub_parsers.add_parser(
        _LISTEN,
        help="listen mode - listen until KeyboardInterrupt",
        parents=[parent_parser, consumer_parser],
    )
    listen_parser.add_argument("-p", "--partition", required=False, type=int, default=None)

    #### NEW FEATURES HERE PLZ
    # replay from, to offset
    # saluki play -o FROMOFFSET TOOFFSET srcbroker/srctopic destbroker/desttopic

    # replay from, to timestamp
    # saluki play -t FROMTIMESTAMP TOTIMESTAMP srcbroker/srctopic destbroker/desttopic

    # saluki consume x messages of y schema
    # saluki consume -f pl72 mybroker:9092/XXX_runInfo -m 10 # get the last pl72 run starts

    # saluki consume x messages of y or z schema
    # saluki consume -f pl72,6s4t mybroker:9092/XXX_runInfo -m 10 # get the last pl72 run starts or 6s4t run stops#

    # saluki bury - dump data on topic to file
    # saluki bury mybroker:9092/topicname -p 0 -f offsetortimestamp -t offsetortimestamp outputfile

    # saluki dig - push data from dump generated by saluki bury to topic 
    # saluki dig mybroker:9092/topicname -p 0 outputfile

    # saluki sniff - broker metadata ie. topic watermarks and num_messages. 
    # saluki sniff mybroker:9092 

    play_parser = sub_parsers.add_parser(
        _PLAY,
        help="replay mode - replay data into another topic",
        parents=[parent_parser],
    )
    play_parser.add_argument("-o", "--offset", help="offsets to replay between (inclusive)", type=int, nargs=2)
    play_parser.add_argument("-t", "--timestamp", help="timestamps to replay between", type=str, nargs=2)


    if len(sys.argv) == 1:
        parser.print_help()
        sys.exit(1)
    args = parser.parse_args()

    if args.kafka_config is not None:
        raise NotImplementedError("-X is not implemented yet.")

    broker, topic = parse_kafka_uri(args.topic)

    if args.log_file:
        logger.addHandler(logging.FileHandler(args.log_file.name))

    if args.command == _LISTEN:
        listen(broker, topic, args.partition, args.filter)
    elif args.command == _CONSUME:
        consume(
            broker,
            topic,
            args.partition,
            args.messages,
            args.offset,
            args.go_forwards,
        )
    elif args.command == _PLAY:
        pass
        #play(src_broker, src_topic, dest_broker, dest_topic, args.offset, args.timestamp)
    elif args.command == _SNIFF:
        print(args.broker)
        pass
    elif args.command == _BURY:
        pass
    elif args.command == _DIG:
        pass

if __name__ == "__main__":
    main()
